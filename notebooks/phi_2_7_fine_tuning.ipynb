{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPqLoBB9DRqM3vHDbD5sAHs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyuichiSaito1/inflation-reddit-usa/blob/main/notebooks/phi_2_7_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using A100 GPU"
      ],
      "metadata": {
        "id": "2l23HPZQAu_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cedQTv7k0gqM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 1. INSTALL REQUIRED PACKAGES\n",
        "# --------------------------------------------------------------------------\n",
        "!pip install transformers==4.44.0 datasets scikit-learn matplotlib torch torchvision torchaudio accelerate bitsandbytes -q"
      ],
      "metadata": {
        "id": "VEp6vMQe0iy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 2. IMPORTS & INITIAL SETUP\n",
        "# --------------------------------------------------------------------------\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    PhiForSequenceClassification, # Directly import the specific model class for Phi-2\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    TrainerCallback\n",
        ")\n",
        "\n",
        "# --- Check GPU Availability ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# --- Time Tracker Callback ---\n",
        "class TimeTrackerCallback(TrainerCallback):\n",
        "    def on_epoch_begin(self, args, state, control, model=None, **kwargs):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, args, state, control, model=None, **kwargs):\n",
        "        elapsed_time = time.time() - self.start_time\n",
        "        print(f\"\\nEpoch {state.epoch:.0f} training time: {elapsed_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "PUN4MgLk0uNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 3. DATA LOADING & PREPARATION\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# --- Define the Classification Prompt ---\n",
        "INFLATION_PROMPT = \"\"\"You are a chief economist at the IMF. I would like you to infer the public perception of inflation from Reddit posts. Please classify each Reddit post into one of the following categories: 0: The post indicates deflation, such as the lower price of goods or services (e.g., \"the prices are not bad\"), affordable services (e.g., \"this champagne is cheap and delicious\"), sales information (e.g., \"you can get it for only 10 dollars.\"), or a declining and buyer's market. 2: The post indicates or includes inflation, such as the higher price of goods or services (e.g., \"it's not cheap\"), the unreasonable cost of goods or services (e.g., \"the food is overpriced and cold\"), consumers struggling to afford necessities (e.g., \"items are too expensive to buy\"), shortage of goods of services, or mention about an asset bubble. 1: The post indicates neither deflation (0) nor inflation (2). This category also includes just questions to a community, social statements not personal experience, factual observations, references to originally expensive or cheap goods or services (e.g., \"a gorgeous and costly dinner\" or \"an affordable Civic\"), website promotion, authors' wishes, or illogical text. Please choose a stronger stance when the text includes both 0 and 2 stances. If these stances are of the same degree, answer 1.\n",
        "Reddit Post: {post}\n",
        "Classification:\"\"\"\n",
        "\n",
        "# --- Load and Process the Dataset ---\n",
        "try:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/world-inflation/data/reddit/production/main-prod-1040.csv', sep=',')\n",
        "    print(f\"Dataset successfully loaded. Shape: {df.shape}\")\n",
        "    print(f\"Class distribution:\\n{df['inflation'].value_counts(normalize=True)}\")\n",
        "\n",
        "    def format_with_prompt(post):\n",
        "        return INFLATION_PROMPT.format(post=post)\n",
        "    df['formatted_body'] = df['body'].apply(format_with_prompt)\n",
        "\n",
        "    # --- Split Data into Training and Validation Sets ---\n",
        "    train_df, val_df = train_test_split(df, test_size=0.25, random_state=42, stratify=df['inflation'])\n",
        "    print(f\"\\nTraining set size: {len(train_df)}\")\n",
        "    print(f\"Validation set size: {len(val_df)}\")\n",
        "\n",
        "    # --- Convert to Hugging Face Datasets ---\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Dataset file not found.\")\n",
        "    print(\"Please upload your CSV file and update the path in the 'pd.read_csv' function.\")\n",
        "\n",
        "    data = {\n",
        "        'body': [\"The price of gas is finally going down.\", \"I can't believe how much a coffee costs now.\", \"What's the weather like today?\"],\n",
        "        'inflation': [0, 2, 1]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    def format_with_prompt(post):\n",
        "        return INFLATION_PROMPT.format(post=post)\n",
        "    df['formatted_body'] = df['body'].apply(format_with_prompt)\n",
        "    train_df, val_df = train_test_split(df, test_size=0.25, random_state=42, stratify=df['inflation'])\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    val_dataset = Dataset.from_pandas(val_df)\n",
        "    print(\"\\nCreated a dummy dataset to allow the script to run.\")"
      ],
      "metadata": {
        "id": "Dz_xb9320yGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 4. MODEL & TOKENIZER INITIALIZATION\n",
        "# --------------------------------------------------------------------------\n",
        "# --- Define Model ---\n",
        "model_name = \"microsoft/phi-2\"\n",
        "print(f\"\\nInitializing model: {model_name}\")\n",
        "\n",
        "# --- Initialize Tokenizer ---\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# --- Load and Configure Model for Sequence Classification ---\n",
        "config = AutoConfig.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3,\n",
        "    id2label={0: \"DEFLATION\", 1: \"NEUTRAL\", 2: \"INFLATION\"},\n",
        "    label2id={\"DEFLATION\": 0, \"NEUTRAL\": 1, \"INFLATION\": 2},\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "model = PhiForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    config=config, # Pass the explicit config\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "print(\"Model and tokenizer initialized successfully.\")\n",
        "\n",
        "# --- Tokenization Function ---\n",
        "def tokenize_function(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples['formatted_body'],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512, # A standard max length for social media posts\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    tokenized['labels'] = examples['inflation']\n",
        "    return tokenized\n",
        "\n",
        "# --- Apply Tokenization ---\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True, remove_columns=val_dataset.column_names)\n",
        "print(\"\\nTokenization complete.\")"
      ],
      "metadata": {
        "id": "7zILDzk31Gw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 5. TRAINING CONFIGURATION\n",
        "# --------------------------------------------------------------------------\n",
        "# --- Define Evaluation Metrics ---\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Get the class with the highest probability\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# --- Set Up Training Arguments ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/world-inflation/data/model/Phi-3.5-fine-tuning\",\n",
        "    logging_dir=\"/content/phi-2-inflation-finetune/Phi-3.5-fine-tuning/logs\",\n",
        "\n",
        "    # Training parameters\n",
        "    num_train_epochs=4,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4, # Adjust based on GPU memory\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,  # Effective batch size = 4 * 4 = 16\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        "    # Evaluation and saving\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2, # Saves the best and the latest checkpoints\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_accuracy\",\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # Efficiency\n",
        "    bf16=True, # Use bfloat16 for better performance on modern GPUs (like L4)\n",
        "    dataloader_pin_memory=False, # Set to False, can sometimes cause issues\n",
        "\n",
        "    # Other settings\n",
        "    remove_unused_columns=True,\n",
        "    logging_steps=10,\n",
        "    seed=42,\n",
        "    report_to=\"none\" # Disable reporting to external services like wandb\n",
        ")"
      ],
      "metadata": {
        "id": "4auYfOt21Hf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 6. INITIALIZE AND START TRAINING\n",
        "# --------------------------------------------------------------------------\n",
        "# --- Initialize Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[TimeTrackerCallback()]\n",
        ")\n",
        "\n",
        "# --- Start Training ---\n",
        "print(\"\\nStarting model training...\")\n",
        "trainer.train()\n",
        "print(\"\\nTraining finished.\")\n",
        "\n",
        "# --- Evaluate Final Model ---\n",
        "print(\"\\nEvaluating the best model on the validation set...\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "ndLCbgW89RcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 5. TRAINING CONFIGURATION\n",
        "# --------------------------------------------------------------------------\n",
        "# --- Define Evaluation Metrics ---\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Get the class with the highest probability\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# --- Set Up Training Arguments ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/world-inflation/data/model/Phi-3.5-fine-tuning\",\n",
        "    logging_dir=\"/content/phi-2-inflation-finetune/Phi-3.5-fine-tuning/logs\",\n",
        "\n",
        "    # Training parameters\n",
        "    num_train_epochs=4,\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=4, # Adjust based on GPU memory\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,  # Effective batch size = 4 * 4 = 16\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "\n",
        "    # Evaluation and saving\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2, # Saves the best and the latest checkpoints\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_accuracy\",\n",
        "    greater_is_better=True,\n",
        "\n",
        "    # Efficiency\n",
        "    bf16=True, # Use bfloat16 for better performance on modern GPUs (like L4)\n",
        "    dataloader_pin_memory=False, # Set to False, can sometimes cause issues\n",
        "\n",
        "    # Other settings\n",
        "    remove_unused_columns=True,\n",
        "    logging_steps=10,\n",
        "    seed=42,\n",
        "    report_to=\"none\" # Disable reporting to external services like wandb\n",
        ")"
      ],
      "metadata": {
        "id": "w6jqOjWf9UT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# 6. INITIALIZE AND START TRAINING\n",
        "# --------------------------------------------------------------------------\n",
        "# --- Initialize Trainer ---\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[TimeTrackerCallback()]\n",
        ")\n",
        "\n",
        "# --- Start Training ---\n",
        "print(\"\\nStarting model training...\")\n",
        "trainer.train()\n",
        "print(\"\\nTraining finished.\")\n",
        "\n",
        "# --- Evaluate Final Model ---\n",
        "print(\"\\nEvaluating the best model on the validation set...\")\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "for key, value in eval_results.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "bSx60RW2Cznl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Vd6ThiiC3U-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}