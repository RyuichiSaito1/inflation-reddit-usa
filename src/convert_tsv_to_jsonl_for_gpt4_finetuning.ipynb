{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyMnMH7PLnNNXpwBCGcAppII",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyuichiSaito1/inflation-reddit-usa/blob/main/src/convert_tsv_to_jsonl_for_gpt4_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPKnxYLNgNjh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install --upgrade openai\n",
        "\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# ☆\n",
        "# Path to the CSV file on Google Drive\n",
        "tsv_file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/validation-data-65.csv'\n",
        "\n",
        "# ☆\n",
        "# Path to save the JSONL file\n",
        "jsonl_file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/validation-data-65.jsonl'\n",
        "\n",
        "def convert_to_new_format(prompt, completion):\n",
        "    # Convert the data to the new JSONL format\n",
        "    new_data = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a chief economist at the IMF. I would like you to infer the public perception of inflation from Reddit posts. Please classify each Reddit post into one of the following categories: 0: The post indicates deflation, such as the lower price of goods or services (e.g., “the prices are not bad”), affordable services (e.g., “this champagne is cheap and delicious”), sales information (e.g., “you can get it for only 10 dollars.”), or a declining and buyer’s  market. 2: The post indicates or includes inflation, such as the higher price of goods or services (e.g., “it’s not cheap”), the unreasonable cost of goods or services (e.g., “the food is overpriced and cold”), consumers struggling to afford necessities (e.g., “items are too expensive to buy”), shortage of goods of services, or mention about an asset bubble. 1: The post indicates neither deflation (0) nor inflation (2). This category also includes just questions to a community, social statements not personal experience, factual observations, references to originally expensive or cheap goods or services (e.g., “a gorgeous and costly dinner” or “an affordable Civic”), website promotion, authors’ wishes, or illogical text. Please choose a stronger stance when the text includes both 0 and 2 stances. If these stances are of the same degree, answer 1.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "            {\"role\": \"assistant\", \"content\": str(completion)} # Surround completion with double quotes\n",
        "        ]\n",
        "    }\n",
        "    return new_data\n",
        "\n",
        "# Read the CSV file, using 'body' as 'Prompt' and 'inflation_score' as 'Completion'\n",
        "df = pd.read_table(tsv_file_path, sep=',', usecols=['body', 'inflation'])\n",
        "\n",
        "# Rename columns to match desired names\n",
        "df = df.rename(columns={'body': 'Prompt', 'inflation': 'Completion'})\n",
        "\n",
        "# Display the number of rows before deduplication\n",
        "print(f\"Input data count (before deduplication): {len(df)}\")\n",
        "\n",
        "# Display count before dropping duplicates\n",
        "before_dedup_count = len(df)\n",
        "print(f\"Count before drop_duplicates: {before_dedup_count}\")\n",
        "\n",
        "# Remove duplicates based on the 'Prompt' and 'Completion' columns\n",
        "df = df.drop_duplicates(subset=['Prompt', 'Completion'])\n",
        "\n",
        "# Display count after dropping duplicates\n",
        "after_dedup_count = len(df)\n",
        "print(f\"Count after drop_duplicates: {after_dedup_count}\")\n",
        "\n",
        "# Display the number of rows after deduplication\n",
        "print(f\"Output data count (after deduplication): {len(df)}\")\n",
        "\n",
        "# Shuffle the data frame\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Convert to JSONL format and save\n",
        "top_10_data = []\n",
        "with open(jsonl_file_path, 'w') as jsonl_file:\n",
        "    for index, row in df.iterrows():\n",
        "        prompt_text = row['Prompt']\n",
        "        completion_text = row['Completion']\n",
        "\n",
        "        new_data = convert_to_new_format(prompt_text, completion_text)\n",
        "\n",
        "        # Write each data as a line in the JSONL file with ensure_ascii=False\n",
        "        jsonl_file.write(json.dumps(new_data, ensure_ascii=False) + '\\n')\n",
        "\n",
        "        # Collect data for top 10 output\n",
        "        top_10_data.append((prompt_text, completion_text))\n",
        "\n",
        "print(f\"Conversion completed. JSONL file saved at: {jsonl_file_path}\")\n",
        "\n",
        "# Display the top 10 data\n",
        "print(\"Top 10 Data:\")\n",
        "for i, (prompt, completion) in enumerate(top_10_data[:10]):\n",
        "    print(f\"{i + 1}. Prompt: {prompt}\\n   Completion: {completion}\\n\")"
      ],
      "metadata": {
        "id": "Om5HiVbfz_xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "alMFArwIPhJ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}