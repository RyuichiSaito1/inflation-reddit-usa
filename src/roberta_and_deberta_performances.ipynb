{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RyuichiSaito1/inflation-reddit-usa/blob/main/src/roberta_and_deberta_performances.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLcDPvNKyk0Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBWLLQ-FyluE"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install accelerate\n",
        "!pip install --upgrade accelerate\n",
        "# After installing, restart the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn4eUZiFzs2B"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training + validation: 1040"
      ],
      "metadata": {
        "id": "aLJTRZtgn9H5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JcVoq0yI4TW8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Function to read data from TSV file using pandas\n",
        "# def read_tsv(file_path):\n",
        "#     data = pd.read_table(file_path, names=['body', 'inflation'], header=0, dtype='object', engine='python')\n",
        "#     return data\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, names=['body', 'inflation'], header=0, dtype='object')\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test data file path (Replace with your Google Drive directory and file)\n",
        "file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/test-data-200.csv'\n",
        "\n",
        "# Read data from TSV file using pandas\n",
        "test_data = read_csv_file(file_path)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "# Encode the test data\n",
        "test_encodings = tokenizer(test_data['body'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Convert the string labels to integers\n",
        "test_labels = [int(label) for label in test_data['inflation']]\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = TestDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize the model\n",
        "model = RobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/world-inflation/data/model/roberta-large-fine-tuning/checkpoint-392/')\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Use the model to predict the labels of the test data\n",
        "for batch in test_loader:\n",
        "    inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
        "    labels = batch['labels'].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    true_labels.extend(labels.tolist())\n",
        "    predicted_labels.extend(predictions.tolist())\n",
        "\n",
        "# Calculate and display accuracy, recall, precision, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "# Display classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "macro_avg = precision.mean(), recall.mean(), f1.mean()\n",
        "micro_avg = precision.sum() / 3, recall.sum() / 3, f1.sum() / 3\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(\"|   Metric     | Accuracy  |  Recall  | Precision|  F1 Score |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "for i in range(3):\n",
        "    print(f\"| Class {i}      |    {accuracy:.2f}   |   {recall[i]:.2f}   |   {precision[i]:.2f}   |   {f1[i]:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Macro Average|    {accuracy:.2f}   |   {recall.mean():.2f}   |   {precision.mean():.2f}   |   {f1.mean():.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Micro Average|    {accuracy:.2f}   |   {recall.sum()/3:.2f}   |   {precision.sum()/3:.2f}   |   {f1.sum()/3:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training + validation: 520"
      ],
      "metadata": {
        "id": "yP9-cU6ya0di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Function to read data from TSV file using pandas\n",
        "# def read_tsv(file_path):\n",
        "#     data = pd.read_table(file_path, names=['body', 'inflation'], header=0, dtype='object', engine='python')\n",
        "#     return data\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, names=['body', 'inflation'], header=0, dtype='object')\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test data file path (Replace with your Google Drive directory and file)\n",
        "file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/test-data-200.csv'\n",
        "\n",
        "# Read data from TSV file using pandas\n",
        "test_data = read_csv_file(file_path)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "# Encode the test data\n",
        "test_encodings = tokenizer(test_data['body'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Convert the string labels to integers\n",
        "test_labels = [int(label) for label in test_data['inflation']]\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = TestDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize the model\n",
        "model = RobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/world-inflation/data/model/roberta-large-fine-tuning-520/checkpoint-392/')\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Use the model to predict the labels of the test data\n",
        "for batch in test_loader:\n",
        "    inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
        "    labels = batch['labels'].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    true_labels.extend(labels.tolist())\n",
        "    predicted_labels.extend(predictions.tolist())\n",
        "\n",
        "# Calculate and display accuracy, recall, precision, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "# Display classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "macro_avg = precision.mean(), recall.mean(), f1.mean()\n",
        "micro_avg = precision.sum() / 3, recall.sum() / 3, f1.sum() / 3\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(\"|   Metric     | Accuracy  |  Recall  | Precision|  F1 Score |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "for i in range(3):\n",
        "    print(f\"| Class {i}      |    {accuracy:.2f}   |   {recall[i]:.2f}   |   {precision[i]:.2f}   |   {f1[i]:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Macro Average|    {accuracy:.2f}   |   {recall.mean():.2f}   |   {precision.mean():.2f}   |   {f1.mean():.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Micro Average|    {accuracy:.2f}   |   {recall.sum()/3:.2f}   |   {precision.sum()/3:.2f}   |   {f1.sum()/3:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n"
      ],
      "metadata": {
        "id": "U7ITU6oAaw1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training + validation: 260"
      ],
      "metadata": {
        "id": "MUTyJLvcZALx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Function to read data from TSV file using pandas\n",
        "# def read_tsv(file_path):\n",
        "#     data = pd.read_table(file_path, names=['body', 'inflation'], header=0, dtype='object', engine='python')\n",
        "#     return data\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, names=['body', 'inflation'], header=0, dtype='object')\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test data file path (Replace with your Google Drive directory and file)\n",
        "file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/test-data-200.csv'\n",
        "\n",
        "# Read data from TSV file using pandas\n",
        "test_data = read_csv_file(file_path)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "# Encode the test data\n",
        "test_encodings = tokenizer(test_data['body'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Convert the string labels to integers\n",
        "test_labels = [int(label) for label in test_data['inflation']]\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = TestDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize the model\n",
        "model = RobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/world-inflation/data/model/roberta-large-fine-tuning-260/checkpoint-147/')\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Use the model to predict the labels of the test data\n",
        "for batch in test_loader:\n",
        "    inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
        "    labels = batch['labels'].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    true_labels.extend(labels.tolist())\n",
        "    predicted_labels.extend(predictions.tolist())\n",
        "\n",
        "# Calculate and display accuracy, recall, precision, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "# Display classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "macro_avg = precision.mean(), recall.mean(), f1.mean()\n",
        "micro_avg = precision.sum() / 3, recall.sum() / 3, f1.sum() / 3\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(\"|   Metric     | Accuracy  |  Recall  | Precision|  F1 Score |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "for i in range(3):\n",
        "    print(f\"| Class {i}      |    {accuracy:.2f}   |   {recall[i]:.2f}   |   {precision[i]:.2f}   |   {f1[i]:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Macro Average|    {accuracy:.2f}   |   {recall.mean():.2f}   |   {precision.mean():.2f}   |   {f1.mean():.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Micro Average|    {accuracy:.2f}   |   {recall.sum()/3:.2f}   |   {precision.sum()/3:.2f}   |   {f1.sum()/3:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n"
      ],
      "metadata": {
        "id": "rjnnUtH3Y95p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training + validation: 130"
      ],
      "metadata": {
        "id": "BgLiC18KVc_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Function to read data from TSV file using pandas\n",
        "# def read_tsv(file_path):\n",
        "#     data = pd.read_table(file_path, names=['body', 'inflation'], header=0, dtype='object', engine='python')\n",
        "#     return data\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, names=['body', 'inflation'], header=0, dtype='object')\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test data file path (Replace with your Google Drive directory and file)\n",
        "file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/test-data-200.csv'\n",
        "\n",
        "# Read data from TSV file using pandas\n",
        "test_data = read_csv_file(file_path)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "# Encode the test data\n",
        "test_encodings = tokenizer(test_data['body'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Convert the string labels to integers\n",
        "test_labels = [int(label) for label in test_data['inflation']]\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = TestDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize the model\n",
        "model = RobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/world-inflation/data/model/roberta-large-fine-tuning-130/checkpoint-75/')\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Use the model to predict the labels of the test data\n",
        "for batch in test_loader:\n",
        "    inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
        "    labels = batch['labels'].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    true_labels.extend(labels.tolist())\n",
        "    predicted_labels.extend(predictions.tolist())\n",
        "\n",
        "# Calculate and display accuracy, recall, precision, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "# Display classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "macro_avg = precision.mean(), recall.mean(), f1.mean()\n",
        "micro_avg = precision.sum() / 3, recall.sum() / 3, f1.sum() / 3\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(\"|   Metric     | Accuracy  |  Recall  | Precision|  F1 Score |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "for i in range(3):\n",
        "    print(f\"| Class {i}      |    {accuracy:.2f}   |   {recall[i]:.2f}   |   {precision[i]:.2f}   |   {f1[i]:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Macro Average|    {accuracy:.2f}   |   {recall.mean():.2f}   |   {precision.mean():.2f}   |   {f1.mean():.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Micro Average|    {accuracy:.2f}   |   {recall.sum()/3:.2f}   |   {precision.sum()/3:.2f}   |   {f1.sum()/3:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n"
      ],
      "metadata": {
        "id": "obHyeOfpU2ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training + validation: 65"
      ],
      "metadata": {
        "id": "kJYGL5fCn5_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3XcGgL6Ea87"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Function to read data from TSV file using pandas\n",
        "# def read_tsv(file_path):\n",
        "#     data = pd.read_table(file_path, names=['body', 'inflation'], header=0, dtype='object', engine='python')\n",
        "#     return data\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, names=['body', 'inflation'], header=0, dtype='object')\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test data file path (Replace with your Google Drive directory and file)\n",
        "file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/test-data-200.csv'\n",
        "\n",
        "# Read data from TSV file using pandas\n",
        "test_data = read_csv_file(file_path)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "\n",
        "# Encode the test data\n",
        "test_encodings = tokenizer(test_data['body'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Convert the string labels to integers\n",
        "test_labels = [int(label) for label in test_data['inflation']]\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = TestDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize the model\n",
        "model = RobertaForSequenceClassification.from_pretrained('/content/drive/MyDrive/world-inflation/data/model/roberta-large-fine-tuning-65/checkpoint-60/')\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Use the model to predict the labels of the test data\n",
        "for batch in test_loader:\n",
        "    inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
        "    labels = batch['labels'].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    true_labels.extend(labels.tolist())\n",
        "    predicted_labels.extend(predictions.tolist())\n",
        "\n",
        "# Calculate and display accuracy, recall, precision, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "# Display classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "macro_avg = precision.mean(), recall.mean(), f1.mean()\n",
        "micro_avg = precision.sum() / 3, recall.sum() / 3, f1.sum() / 3\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(\"|   Metric     | Accuracy  |  Recall  | Precision|  F1 Score |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "for i in range(3):\n",
        "    print(f\"| Class {i}      |    {accuracy:.2f}   |   {recall[i]:.2f}   |   {precision[i]:.2f}   |   {f1[i]:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Macro Average|    {accuracy:.2f}   |   {recall.mean():.2f}   |   {precision.mean():.2f}   |   {f1.mean():.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Micro Average|    {accuracy:.2f}   |   {recall.sum()/3:.2f}   |   {precision.sum()/3:.2f}   |   {f1.sum()/3:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeBERTa: Training + validation: 1040"
      ],
      "metadata": {
        "id": "zqqB9SeHZUua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Function to read data from TSV file using pandas\n",
        "# def read_tsv(file_path):\n",
        "#     data = pd.read_table(file_path, names=['body', 'inflation'], header=0, dtype='object', engine='python')\n",
        "#     return data\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, names=['body', 'inflation'], header=0, dtype='object')\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test data file path (Replace with your Google Drive directory and file)\n",
        "file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/test-data-200.csv'\n",
        "\n",
        "# Read data from CSV file using pandas\n",
        "test_data = read_csv_file(file_path)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-large')\n",
        "\n",
        "# Encode the test data\n",
        "test_encodings = tokenizer(test_data['body'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Convert the string labels to integers\n",
        "test_labels = [int(label) for label in test_data['inflation']]\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = TestDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize the model (Update path to your DeBERTaV3 checkpoint)\n",
        "model = DebertaV2ForSequenceClassification.from_pretrained('/content/drive/MyDrive/world-inflation/data/model/deberta-large-fine-tuning-1040/checkpoint-588/')\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Use the model to predict the labels of the test data\n",
        "for batch in test_loader:\n",
        "    inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
        "    labels = batch['labels'].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    true_labels.extend(labels.tolist())\n",
        "    predicted_labels.extend(predictions.tolist())\n",
        "\n",
        "# Calculate and display accuracy, recall, precision, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "# Display classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "macro_avg = precision.mean(), recall.mean(), f1.mean()\n",
        "micro_avg = precision.sum() / 3, recall.sum() / 3, f1.sum() / 3\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(\"|   Metric     | Accuracy  |  Recall  | Precision|  F1 Score |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "for i in range(3):\n",
        "    print(f\"| Class {i}      |    {accuracy:.2f}   |   {recall[i]:.2f}   |   {precision[i]:.2f}   |   {f1[i]:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Macro Average|    {accuracy:.2f}   |   {recall.mean():.2f}   |   {precision.mean():.2f}   |   {f1.mean():.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Micro Average|    {accuracy:.2f}   |   {recall.sum()/3:.2f}   |   {precision.sum()/3:.2f}   |   {f1.sum()/3:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")"
      ],
      "metadata": {
        "id": "2C96_3DuaXl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeBERTa: Training + validation: 65"
      ],
      "metadata": {
        "id": "8o2UbMBhmoB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# # Function to read data from TSV file using pandas\n",
        "# def read_tsv(file_path):\n",
        "#     data = pd.read_table(file_path, names=['body', 'inflation'], header=0, dtype='object', engine='python')\n",
        "#     return data\n",
        "\n",
        "def read_csv_file(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, names=['body', 'inflation'], header=0, dtype='object')\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Test data file path (Replace with your Google Drive directory and file)\n",
        "file_path = '/content/drive/MyDrive/world-inflation/data/reddit/production/test-data-200.csv'\n",
        "\n",
        "# Read data from CSV file using pandas\n",
        "test_data = read_csv_file(file_path)\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-large')\n",
        "\n",
        "# Encode the test data\n",
        "test_encodings = tokenizer(test_data['body'].tolist(), truncation=True, padding=True)\n",
        "\n",
        "# Convert the string labels to integers\n",
        "test_labels = [int(label) for label in test_data['inflation']]\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = TestDataset(test_encodings, test_labels)\n",
        "\n",
        "# Initialize the model (Update path to your DeBERTaV3 checkpoint)\n",
        "model = DebertaV2ForSequenceClassification.from_pretrained('/content/drive/MyDrive/world-inflation/data/model/deberta-large-fine-tuning-65/checkpoint-96/')\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Lists to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Use the model to predict the labels of the test data\n",
        "for batch in test_loader:\n",
        "    inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
        "    labels = batch['labels'].to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "    true_labels.extend(labels.tolist())\n",
        "    predicted_labels.extend(predictions.tolist())\n",
        "\n",
        "# Calculate and display accuracy, recall, precision, and F1 score\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels, average=None)\n",
        "precision = precision_score(true_labels, predicted_labels, average=None)\n",
        "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
        "\n",
        "# Display classification report and confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, predicted_labels))\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "macro_avg = precision.mean(), recall.mean(), f1.mean()\n",
        "micro_avg = precision.sum() / 3, recall.sum() / 3, f1.sum() / 3\n",
        "\n",
        "# Display metrics for each class and macro/micro averages\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(\"|   Metric     | Accuracy  |  Recall  | Precision|  F1 Score |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "for i in range(3):\n",
        "    print(f\"| Class {i}      |    {accuracy:.2f}   |   {recall[i]:.2f}   |   {precision[i]:.2f}   |   {f1[i]:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Macro Average|    {accuracy:.2f}   |   {recall.mean():.2f}   |   {precision.mean():.2f}   |   {f1.mean():.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")\n",
        "print(f\"| Micro Average|    {accuracy:.2f}   |   {recall.sum()/3:.2f}   |   {precision.sum()/3:.2f}   |   {f1.sum()/3:.2f}   |\")\n",
        "print(\"+--------------+-----------+----------+----------+----------+\")"
      ],
      "metadata": {
        "id": "MX9_XH6ufxHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cvf10GBvomkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "authorship_tag": "ABX9TyO581zMfwE/r59fsk+hFPQ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}